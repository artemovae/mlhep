{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "import user_test_submission as submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from clusterer import Clusterer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "import math\n",
    "from metrics import predictor\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Pattern Recognition using Linear Approximation of a Track\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Track pattern recognition is an early step of the reconstruction of data coming from a particle detector. It recognizes tracks among the subdetectors hits. Reconstructed track parameters allow to estimate the particle deviation in a magnetic field, and thus reconstruct its charge and momentum. This information is used for the reconstruction of the decay vertex, to identify the mother particle and for further particle identification.\n",
    "\n",
    "There is wide variety of the track pattern recognition methods. They differ in how they process the hits, what kind of tracks they are able to recognize and which requirements these tracks should satisfy. Therefore, specifics of an experiment and the detector geometry affect the tracking performance and track pattern recognition methods should be adapted to it accordingly.\n",
    "\n",
    "In this notebook a track pattern recognition for a 2D detector with circular geometry and uniform magnetic field is considered. The detector schema with hits and tracks of an event is shown in the figure below. The challenge is to recognize tracks of an event with the highest efficiecny. It supposed that one hit can belong to only one track. \n",
    "\n",
    "<img src=\"pic/detector.png\" /> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Quick Glossary\n",
    "\n",
    "We use the following vocabulary in the context of practice session. It may be slightly different from the general high-energy physics context. Some terms are not used in the workbook, but kept here in case they are used in the discussions.\n",
    "\n",
    "* **event**: a recorded (or simulated) collision in which many particles are present, the basic unit of particle physics data\n",
    "* **pixel**: the smallest detector unit\n",
    "* **hit**: a pixel through which a particle has passed and left signal in a given event\n",
    "* **cluster**: a set of hits, belonging (or predicted to be belonging) to the trajectory of a single particle\n",
    "* **reconstruct**: same thing as predict, but may also refer to further derived quantities\n",
    "* **track**: a reconstructed particle, that is, a cluster but also including additional derived information, such as the overall curvature and angle\n",
    "* **vertex**: the point close to the center of the detector, from which the particles have originated\n",
    "* **impact parameter**: the shortest distance between a track and the origin\n",
    "* **(momentum/angle/etc) resolution** : width of the normal distribution of the difference between a predicted quantity and the true value of that quantity\n",
    "\n",
    "## Objectives\n",
    "\n",
    "The main objective of the challenge is the optimal matching of the hits in an event. The positions of the hits in the detector are provided as input data, and the user is expected to implement a clustering scheme (trained on data if needed), so that every hit is assigned to a cluster id.\n",
    "\n",
    "The value of the cluster id itself is not relevant for the task, what is relevant is which hits are clustered together, and whether this clustering corresponds well to the input particles. The score function that describes this is included in the notebook, and details will be mentioned there.\n",
    "\n",
    "## Application\n",
    "\n",
    "The user is expected to implement the class `clusterer.py`, which contains the `__init__`, `fit`, and `predict_single_event` functions.\n",
    "\n",
    "* **`__init__`** is where parameters should be set.\n",
    "* **`fit`** is the training function (not to be confused with track-fitting), where the algorithm has access to the ground-truth. This function is to be run once on an input array that contains a set of training events. The user is able to implement any event-level or particle-level segmentation of the input array in order to set up the training in any desired way.\n",
    "* **`predict_single_event`** is the function to reconstruct the hit clusters (tracks), returning an array of predicted (reconstructed) ids associated to each hit in the input array. This function takes only the hits from a single event as input, with the event_id dropped, and the RAMP machinery takes care of running this function on each event.\n",
    "\n",
    "The **task**  is to implement this class in a way that the predict_single_event function returns a numpy array of assigned cluster ids. At any level of this task, machine-learning techniques can be employed for sub-tasks defined by the user.\n",
    "\n",
    "## Detector\n",
    "\n",
    "Image from the Atlas experiment:\n",
    "\n",
    "<img src=\"pic/atlas2009.png\" /> <br>\n",
    "\n",
    "The data provided to the user is a list of hit positions from a simple toy detector model that mimics the Atlas detector design (which is generic enough for recent silicon-based tracking detectors). The detector has an onion-like geometry with 9 layers surrounding the origin with polar distances of $R = [39,85,155,213,271,405,562,762,1000]$ cm. These layers have a very small thicknesses compared to the distances, therefore the thickness can be neglected.\n",
    "\n",
    "Each layer is segmented in azimuth with high granularity. There are ($2\\pi$R/pitch)+1 pixels in every layer, where pitch is 0.025 cm for layers 0-4 and 0.05 cm for layers 5-9.\n",
    "\n",
    "Every \"pixel\" corresponds to the smallest detector unit defined by `layer` and `iphi` (azimuthal index).\n",
    "\n",
    "## Simulation\n",
    "\n",
    "The task uses a toy model for particle generation and simulation, in which a Poisson distribution is sampled to determine the number of particles in each event, with an average of 10 particles per event.\n",
    "\n",
    "The particles are sampled uniformly in azimuth and momentum with bounds on the momentum. Each particle originates from a vertex that is also randomly sampled from a narrow normal distribution around the origin. The proper dimensions of the momentum and position and determination of these values for the tracks are beyond the scope of the challenge.\n",
    "\n",
    "The particles generated this way are simulated in a uniform magnetic field. The detector material is considered to cause multiple-scattering, and this is implemented as a random rotation of the particle momentum at every detector position, sampled from a narrow normal distribution that roughly corresponds to the material of the Atlas tracker.\n",
    "\n",
    "In addition, some hit inefficiency is simulated by a random drop of some hits (with 3% probability), and a particle stopping probability of 1% is applied at each layer to simulate effects of hadronic interactions. Keeping these in mind, the algorithms might be desired to be able to handle cases when the particle doesn't have a hit on every layer.\n",
    "\n",
    "Since the detector has a very high granularity in azimuth, the cases where two particles pass through a single pixel are neglected (less than 0.2% probability).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "\n",
    "This notebook demonstrate how linear approximation of a track can be used for track pattern recognition. The notebook describes input data, the track pattern recognition method and qualyti metrics, and shows how to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo pip install sklearn==0.18.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>layer</th>\n",
       "      <th>iphi</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53253</td>\n",
       "      <td>53.900430</td>\n",
       "      <td>-265.585662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>37216</td>\n",
       "      <td>-47.614439</td>\n",
       "      <td>-402.191329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7181</td>\n",
       "      <td>-4.253919</td>\n",
       "      <td>-38.767308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7937</td>\n",
       "      <td>44.418132</td>\n",
       "      <td>148.499258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7657</td>\n",
       "      <td>7.588600</td>\n",
       "      <td>-38.254583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id  cluster_id  layer   iphi          x           y\n",
       "0         3           4      4  53253  53.900430 -265.585662\n",
       "1         3           1      5  37216 -47.614439 -402.191329\n",
       "2         3           1      0   7181  -4.253919  -38.767308\n",
       "3         3           3      2   7937  44.418132  148.499258\n",
       "4         3           4      0   7657   7.588600  -38.254583"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"public_train\"\n",
    "data = pandas.read_csv('datasets/'+name+'.csv', index_col=False)\n",
    "#data = data[data['event_id'].values < 100]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['event_id', 'cluster_id']].values\n",
    "X = data.drop(['cluster_id'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the hits in a single event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = 42\n",
    "event_indices = (X[:, 0] == event_id)\n",
    "X_event = X[event_indices, 1:] # event_id column dropped\n",
    "pixel_x = X_event[:, 2]\n",
    "pixel_y = X_event[:, 3]\n",
    "tracks = y[event_indices][: ,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits from all tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pixel_x, pixel_y)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the algorithm will see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hits from a single track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_id = 2\n",
    "track_hits = (tracks == track_id)\n",
    "plt.scatter(pixel_x[track_hits], pixel_y[track_hits])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, ideally, our algorithm wants to assign specific ids to all hits in a way that corresponds to the particle. The perfect algorithm will split the event into various tracks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = ['k', 'b', 'y', 'g', 'r', 'k', 'b']\n",
    "for track_id in np.unique(tracks):\n",
    "    track_hits = (tracks == track_id)\n",
    "    plt.scatter(pixel_x[track_hits], pixel_y[track_hits], color=cmap[int(track_id) % 7])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "event_ids = numpy.unique(data['event_id'].values)\n",
    "\n",
    "event_ids_train, event_ids_test = train_test_split(event_ids, \n",
    "                                                   test_size=1000, \n",
    "                                                   random_state=42)\n",
    "\n",
    "X_train, y_train = X[data['event_id'].isin(event_ids_train)], y[data['event_id'].isin(event_ids_train)]\n",
    "X_test, y_test = X[data['event_id'].isin(event_ids_test)], y[data['event_id'].isin(event_ids_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track Pattern Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Density-based clustering of a Track\n",
    "\n",
    "This method is based on the DNSCAN clustering of a track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clusterer import Clusterer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "ctr = Clusterer(cluster=DBSCAN(eps=0.05, min_samples=1))\n",
    "\n",
    "ctr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 30.6 ms, total: 1.41 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from metrics import predictor\n",
    "\n",
    "y_pred_test = predictor(ctr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.1414\n"
     ]
    }
   ],
   "source": [
    "score = submission.score_function(y_test, y_pred_test)\n",
    "print(\"Score: {:1.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN-based clustering of a Track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a basic LSTM model architecture used to classify hits for one track. The LSTM and a fully-connected layer with a softmax activation read the pixel arrays and predict which pixels belong to the target track.\n",
    "\n",
    "<img src=\"pic/model.png\" /> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class det_geo():\n",
    "    layer_r = np.array([39,85,155,213,271,405,562,762,1000])\n",
    "    layer_pitch = np.array([0.025, 0.025, 0.025, 0.025, 0.025,\n",
    "                            0.05, 0.05, 0.05, 0.05])\n",
    "    num_layers = layer_r.shape[0]\n",
    "    num_pixels = (2 * np.pi * layer_r / layer_pitch + 1).astype(np.int)\n",
    "    max_phi = num_pixels # backwards compatibility\n",
    "\n",
    "def rebin_phi(phi_bin, nbin, layer):\n",
    "    return (phi_bin * float(nbin) /\n",
    "            det_geo.num_pixels[layer.astype(np.int)]).astype(np.int)\n",
    "\n",
    "def rescale_phi(phi_bin, factor):\n",
    "    return (phi_bin * factor).astype(np.int)\n",
    "\n",
    "def get_phi(phi_bin, layer, phi_scale=1.):\n",
    "    return 2*np.pi*phi_bin / math.ceil(det_geo.num_pixels[layer]*phi_scale)\n",
    "\n",
    "def get_phi_bin(phi, layer, phi_scale=1.):\n",
    "    # Is this rounding the right way?\n",
    "    #return int((phi/(2*np.pi)) * det_geo.num_pixels[layer] * phi_scale)\n",
    "    return int(phi_scale * det_geo.num_pixels[layer] * phi / (2*np.pi))\n",
    "\n",
    "def get_phi_bin_range(phi_bin, layer, window_size=15, phi_scale=1.):\n",
    "    phi = get_phi(phi_bin, layer, phi_scale)\n",
    "    phi_bins = np.array([get_phi_bin(phi, i, phi_scale)\n",
    "                         for i in range(det_geo.num_layers)])\n",
    "    return (phi_bins - window_size//2, phi_bins + window_size//2)\n",
    "\n",
    "def build_model(num_hidden, length, dim,\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer='Nadam', metrics=['accuracy']):\n",
    "    inputs = layers.Input(shape=(length, dim))\n",
    "    hidden = layers.LSTM(output_dim=num_hidden, return_sequences=True)(inputs)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(dim, activation='softmax'))(hidden)\n",
    "    model = models.Model(input=inputs, output=outputs)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clusterer(BaseEstimator):\n",
    "    def __init__(self, min_cos_value=0.9):\n",
    "        \"\"\"\n",
    "        Track Pattern Recognition based on the connections between\n",
    "        two nearest hits from two nearest detector layers.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        min_cos_value : float\n",
    "            Minimum cos value between two nearest segments of the track.\n",
    "        \"\"\"\n",
    "        self.min_cos_value = min_cos_value\n",
    "        self.phi_scale = 1/50.\n",
    "        self.num_phi_bins = np.ceil(det_geo.num_pixels * self.phi_scale).astype(np.int)\n",
    "        self.window_size = 501\n",
    "        self.hidden_dim = 50\n",
    "        self.model = build_model(self.hidden_dim,\n",
    "                                 det_geo.layer_r.shape[0],\n",
    "                                 self.window_size)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.batch_size = 50\n",
    "        self.num_epoch = 2\n",
    "        \n",
    "        # safety check - shouldn't be needed anymore\n",
    "        #assert (self.num_phi_bins*2 >= self.window_size).all()\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        evids, lays, phis = (X[:,0].astype(np.int),\n",
    "                             X[:,1].astype(np.int),\n",
    "                             X[:,2].astype(np.int))\n",
    "        phis = rescale_phi(phis, self.phi_scale)\n",
    "        #unique_evids = np.unique(evids)\n",
    "        #num_event = unique_evids.shape[0]\n",
    "        \n",
    "        # Count the number of first-layer hits, which will be my seeds\n",
    "        seed_idx = np.where(lays == 0)[0]\n",
    "        num_seeds = seed_idx.size\n",
    "        print( 'Number of seeds: %d' % num_seeds)\n",
    "\n",
    "        print( 'Preparing training data...')\n",
    "        # Training input will contain the seed hit followed by the rest of the event\n",
    "        self.train_input = np.zeros((num_seeds, det_geo.num_layers,\n",
    "                                     self.window_size))\n",
    "        # Training targets will be images of the individual signal tracks\n",
    "        self.train_target = np.zeros_like(self.train_input)\n",
    "        \n",
    "        # Loop over training samples to prepare (seeds)\n",
    "        for i_sample in range(num_seeds):\n",
    "            i_seed = seed_idx[i_sample]\n",
    "\n",
    "            # Find all the hits from this event\n",
    "            evid = y[i_seed, 0]\n",
    "            ev_idxs = (evids == evid)\n",
    "            ev_lays, ev_phis = lays[ev_idxs], phis[ev_idxs]\n",
    "            \n",
    "            # Transform global phi bins into window pixel number\n",
    "            pix_min, _ = get_phi_bin_range(phis[i_seed], lays[i_seed], self.window_size)\n",
    "            ev_pixs = ev_phis - pix_min[ev_lays]\n",
    "            #print(ev_pixs, ev_phis, pix_min[ev_lays])\n",
    "            \n",
    "            # Find the hits which wrap around at phi=0 and are outside the window\n",
    "            outside_idxs = np.logical_or(ev_pixs < 0, ev_pixs >= self.window_size)\n",
    "            wrap_pixs_up = ev_pixs - self.num_phi_bins[ev_lays]\n",
    "            wrap_pixs_dn = ev_pixs + self.num_phi_bins[ev_lays]\n",
    "            wrap_pixs_up_idxs = np.logical_and(wrap_pixs_up >= 0, outside_idxs)\n",
    "            wrap_pixs_dn_idxs = np.logical_and(wrap_pixs_dn < self.window_size, outside_idxs)\n",
    "            ev_pixs[wrap_pixs_up_idxs] = wrap_pixs_up[wrap_pixs_up_idxs]\n",
    "            ev_pixs[wrap_pixs_dn_idxs] = wrap_pixs_dn[wrap_pixs_dn_idxs]\n",
    "\n",
    "            # Now select all hits contained in the window\n",
    "            sample_idxs = np.logical_and(ev_pixs >= 0, ev_pixs < self.window_size)\n",
    "            sample_lays, sample_pixs = ev_lays[sample_idxs], ev_pixs[sample_idxs]\n",
    "\n",
    "            # Fill the input first layer with just the seed hit\n",
    "            self.train_input[i_sample, 0, self.window_size//2] = 1\n",
    "            #print(i_sample, 0, self.window_size//2)\n",
    "            # Fill the other layers with all remaining event hits\n",
    "            #print(i_sample, sample_lays[sample_lays>0], sample_pixs[sample_lays>0])\n",
    "            self.train_input[i_sample, sample_lays[sample_lays>0], sample_pixs[sample_lays>0]] = 1\n",
    "            \n",
    "            # Fill target with all hits from this track\n",
    "            ev_trkids = y[ev_idxs][:,1]\n",
    "            ev_sig_idxs = ev_trkids == y[i_seed,1]\n",
    "            #print ev_pixs[ev_sig_idxs]\n",
    "            self.train_target[i_sample, ev_lays[ev_sig_idxs], ev_pixs[ev_sig_idxs]] = 1\n",
    "\n",
    "        print( 'Starting training...'  )    \n",
    "        self.history = self.model.fit(\n",
    "            self.train_input, self.train_target,\n",
    "            batch_size=self.batch_size, nb_epoch=self.num_epoch)\n",
    "\n",
    "    def predict_single_event(self, X_event):\n",
    "        \n",
    "        # We need to now transform the data into the format\n",
    "        # needed for my algorithm\n",
    "        lays, phis = (X_event[:,0].astype(np.int),\n",
    "                      X_event[:,1].astype(np.int))\n",
    "        # Rebin phi\n",
    "        phis = rescale_phi(phis, self.phi_scale)\n",
    "        \n",
    "        # First, find the seeds\n",
    "        seed_idx = np.where(lays == 0)[0]\n",
    "        num_seeds = seed_idx.size\n",
    "#         print ('Number of seeds: %d' % num_seeds  )  \n",
    "        \n",
    "        # Prepare the model inputs\n",
    "        self.test_input = np.zeros((num_seeds, det_geo.num_layers,\n",
    "                                    self.window_size))\n",
    "        # Save the window coordinates for each input as well\n",
    "        self.window_min = np.zeros((num_seeds, det_geo.num_layers), dtype=int)\n",
    "        \n",
    "        # Loop over seeds to prepare\n",
    "        for i_sample in range(num_seeds):\n",
    "            i_seed = seed_idx[i_sample]\n",
    "            \n",
    "            # Transform global phi bins into window pixel number\n",
    "            pix_min, _ = get_phi_bin_range(phis[i_seed], lays[i_seed], self.window_size)\n",
    "            pixs = phis - pix_min[lays]\n",
    "            self.window_min[i_sample] = pix_min\n",
    "            \n",
    "            # Find the hits which wrap around at phi=0 and are outside the window\n",
    "            outside_idxs = np.logical_or(pixs < 0, pixs >= self.window_size)\n",
    "            wrap_up = pixs - self.num_phi_bins[lays]\n",
    "            wrap_dn = pixs + self.num_phi_bins[lays]\n",
    "            wrap_up_idxs = np.logical_and(wrap_up >= 0, outside_idxs)\n",
    "            wrap_dn_idxs = np.logical_and(wrap_dn < self.window_size, outside_idxs)\n",
    "            pixs[wrap_up_idxs] = wrap_up[wrap_up_idxs]\n",
    "            pixs[wrap_dn_idxs] = wrap_dn[wrap_dn_idxs]\n",
    "\n",
    "            # Now select all hits contained in the window\n",
    "            sample_idxs = np.logical_and(pixs >= 0, pixs < self.window_size)\n",
    "            sample_lays, sample_pixs = lays[sample_idxs], pixs[sample_idxs]\n",
    "\n",
    "            # Fill the input first layer with just the seed hit\n",
    "            #print 'Seed pixel:', pixs[i_seed]\n",
    "            self.test_input[i_sample, 0, int(pixs[i_seed])] = 1\n",
    "            # Fill the other layers with all remaining event hits\n",
    "            self.test_input[i_sample, sample_lays[sample_lays>0], sample_pixs[sample_lays>0]] = 1\n",
    "        \n",
    "        # Run the model prediction\n",
    "        self.test_pred = self.model.predict(self.test_input)\n",
    "        \n",
    "        # Now we need to loop over all hits and decide which\n",
    "        # track they belong to\n",
    "        trkid = np.zeros(X_event.shape[0])\n",
    "        for i in range(trkid.shape[0]):\n",
    "            lay, phi = lays[i], phis[i]\n",
    "            \n",
    "            scores = np.zeros(num_seeds)\n",
    "            \n",
    "            # Loop over each seed\n",
    "            for j in range(num_seeds):\n",
    "                pred = self.test_pred[j]\n",
    "                window_min = self.window_min[j]\n",
    "                \n",
    "                # Need to transform into the window coordinates of each seed\n",
    "                pix = phi - window_min[lay]\n",
    "                # Correct for wrap-around\n",
    "                if pix < 0 and pix < self.window_size - self.num_phi_bins[lay]:\n",
    "                    pix = pix + self.num_phi_bins[lay]\n",
    "                elif pix >= self.window_size and pix >= self.num_phi_bins[lay]:\n",
    "                    pix = pix - self.num_phi_bins[lay]\n",
    "                \n",
    "                # Check the association score\n",
    "                if pix >= 0 and pix < self.window_size:\n",
    "                    scores[j] = pred[lay, pix]\n",
    "            \n",
    "            # Get the list of track scores\n",
    "            #scores = self.test_pred[:, lays[i], phis[i]]\n",
    "            #print 'scores:', scores\n",
    "            \n",
    "            # Select the best score\n",
    "            best = np.argmax(scores)\n",
    "\n",
    "            # If the best isn't good enough, it's possible that\n",
    "            # a track was missing a hit on the first layer.\n",
    "            # We may be able to improve score by assigning all such\n",
    "            # tracks to a new class (rather than 'unassigned')\n",
    "            if scores[best] < 1 / float(self.window_size):\n",
    "                #print 'Bad best:', scores[best]\n",
    "                best = scores.shape[0]\n",
    "\n",
    "            trkid[i] = best\n",
    "        \n",
    "        return trkid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seeds: 38565\n",
      "Preparing training data...\n",
      "Starting training...\n",
      "Epoch 1/2\n",
      "38565/38565 [==============================] - 16s 422us/step - loss: 2.2024 - acc: 0.5019\n",
      "Epoch 2/2\n",
      "38565/38565 [==============================] - 16s 404us/step - loss: 0.5678 - acc: 0.8189\n"
     ]
    }
   ],
   "source": [
    "ctr = Clusterer()\n",
    "ctr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 9, 501)            0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 9, 50)             110400    \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 9, 501)            25551     \n",
      "=================================================================\n",
      "Total params: 135,951\n",
      "Trainable params: 135,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ctr.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = predictor(ctr, X_test[:, 1:], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9326\n"
     ]
    }
   ],
   "source": [
    "score = submission.score_function(y_test, y_pred_test)\n",
    "print(\"Score: {:1.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: implement some visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks:\n",
    "1. Define a new function ```build_deep_model``` and create a new model: add a few dense layers before and after the LSTM layer. Play a bit with the shapes of the layers.\n",
    "2. Define a new function ```build_bidirectional_model``` and create a new model: use a bidirectional LSTM layers instead of a single LSTM layer. Use ```keras.layers.Bidirectional``` layer wrapper. Play a bit with the shapes of the layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_model(num_hidden, length, dim,\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer='Nadam', metrics=['accuracy']):\n",
    "    inputs = layers.Input(shape=(length, dim))\n",
    "    hidden = layers.TimeDistributed(layers.Dense(num_hidden, activation='softmax'))(inputs)\n",
    "    hidden = layers.LSTM(output_dim=num_hidden, return_sequences=True)(hidden)\n",
    "    hidden = layers.TimeDistributed(layers.Dense(num_hidden, activation='softmax'))(hidden)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(dim, activation='softmax'))(hidden)\n",
    "    model = models.Model(input=inputs, output=outputs)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_bidirectional_model(num_hidden, length, dim,\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer='Nadam', metrics=['accuracy']):\n",
    "    inputs = layers.Input(shape=(length, dim))\n",
    "    hidden = layers.Bidirectional(layers.LSTM(output_dim=num_hidden, return_sequences=True))(inputs)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(dim, activation='softmax'))(hidden)\n",
    "    model = models.Model(input=inputs, output=outputs)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
